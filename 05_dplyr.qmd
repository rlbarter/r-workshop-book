---
title: "Data Frames in the Tidyverse"
format: html
editor_options: 
  chunk_output_type: console
---


R is an open source programming language, which means that anyone can extend it by creating their own R functions. When someone creates a collection of related R functions, they typically bundle them into what is called a "package" or a "library" (I use these terms interchangeably), which can then be downloaded and used by other people.


I don't think it's an exaggeration to say that you probably wouldn't be learning R today were it not for one particular package called the "tidyverse" (so named because it helps you create and work with ["tidy" data](https://vita.had.co.nz/papers/tidy-data.pdf)). The tidyverse is actually a collection of several important R packages, including one called "dplyr" and another one called "ggplot2" (this chapter will introduce dplyr and you'll get to know ggplot2 in the next chapter). 

Although the tidyverse was originally created by Hadley Wickham, it has since grown to include contributions from hundreds of brilliant R developers. Together, they have revolutionized the way we use R for the better. The tidyverse and its impacts are a true testament to the power of the open source community.



## Installing and Loading R packages


R packages are collections of "add-on" R functions that you can "load" into your R session to provide additional functionality. 

To use functions from a package, you need to do two things:

1. Install the package on your computer. **You only need to do this once.**

2. Load your package into your current R session. **You need to do this every time you start a new R session (i.e., every time you open up RStudio).**

I like to think of *installing* an R package like installing a new application onto your computer. You only ever need to install the application once (unless you're updating it), but you need to open it every time you want to use it (in this analogy, loading a library is like "opening" your application).


### Installing an R package

So to get started with dplyr, ggplot2, and the other tidyverse packages, we need to *install* them. But to make our lives easier, we can simultaneously install all the tidyverse packages (ggplot2, dplyr, reshape, purrr, readr, and many others) by just installing the "tidyverse" package itself.


To install the "tidyverse" package (or any other package), write the following code *directly into your console* (I do *not* recommend saving this code in a quarto document or R script, because once you've run this code, you don't need to run it again):

```{r}
#| eval: false
# write this code directly into the console: 
install.packages("tidyverse")
```

Note that you need to be connected to the internet to install a package (since it's like downloading an application from the internet.)

### Loading an R package

Once you've installed it, every time you want to *use* an installed R package in a new R session, you need to *"load"* it using the library() function. 

```{r}
library(tidyverse)
```

Since you need to run this every time you open RStudio, you should include this code in the first chunk of your quarto document or R script.

When you load libraries into R, you'll often see a lot of message "output" (what I like to call "chatter"). This output (such as that printed below the `library(tidyverse)` chunk above) is completely normal. 
But if you're loading a library in a quarto document, you might want to hide the message output in the resulting rendered document. To do that, you can use the chunk option `#| message: false`, as in:

```{{r}}
#| message: false
library(dplyr)
```

Then the library loading "chatter" will be hidden from the rendered HTML document.



## Tibbles and the `read_csv()` function

In the last chapter, we used a "base R" function (`read.csv()`) to load our gapminder dataset. The term "*base R*" refers to functions that are always available in R and do not require you to load any additional libraries.


While it's perfectly fine to continue to use this `read.csv()` function, I recommend instead using a slightly different function that has an underscore instead of a period in its name: `read_csv()`. This function does pretty much the same thing as `read.csv()` but it is part of the tidyverse and is a little bit more efficient and user-friendly than `read.csv()`.

Let's use `read_csv()` (the tidyverse version of `read.csv()`) to load the gapminder dataset:

```{r}
gapminder <- read_csv("data/gapminder.csv")
```


This function also tends to print out some "chatter" message text, which I can hide from my rendered quarto output by providing the `#| message: false` chunk option at the top of the relevant code chunk.

If you ran this in your own console and you got an error saying "*Error in read_csv("data/gapminder.csv") : could not find function "read_csv"*", make sure you have installed the tidyverse *and have run the code `library(tidyverse)` in your console*! R can only find the `read_csv()` function if you have loaded the tidyverse!

Now let's take a look at `gapminder` (*without using `head()`*)

```{r}
gapminder
```


Do you notice any differences between this version of `gapminder` (that has been loaded using the tidyverse `read_csv()`) and the version from the previous chapter (that was loaded using the base R `read.csv()` function)?

To make your life easier, here is the version of `gapminder` that we loaded with the base R `read.csv()` function:

```{r}
#| attr-output: 'style="height: 400px"'
gapminder_base_r <- read.csv("data/gapminder.csv")
gapminder_base_r
```

Here are the main differences:



1. The version loaded using  the base R `read.csv()` function prints out the first 1000 rows (though I've kindly put them all in a nice scrolly box for you), whereas the version loaded using the tidyverse `read_csv()` function only prints out the first 10 rows (and it also only displays the first few columns whenever your dataset contains a large number of columns).

2. The version loaded using the tidyverse `read_csv()` function will also show you what *type*/*class* each columns has. Look underneath the column names of the tidyverse `read_csv()` version of `gapminder` above. See the `<chr>` and `<dbl>` symbols? These mean "character" and "double" ("double" means "numeric with decimals"), respectively.  

3. The tidyverse `read_csv()` version prints out some information at the top that says `# A tibble: 1,704 × 6`, which tells us that our data frame has 1,704 rows and 6 columns. 

What's a "tibble"? It turns out that `read_csv()` doesn't actually load your data in as a data frame. It loads your data in as a *"tibble"*. While tibbles have some fancy features, for our purposes, you can just think of a tibble as a data frame that looks slightly different when printed. Note that I will usually use the term "data frame" even if the object is technically a tibble. 


## The dplyr library

So we've now loaded the tidyverse library and we've loaded our gapminder data using `read_csv()`. The code we've written so far in this chapter is essentially just:

```{r}
#| message: false
library(tidyverse)
gapminder <- read_csv("data/gapminder.csv")
```

When we loaded the "tidyverse" library, this also loaded the "dplyr" library (along with several others.)


The dplyr library is probably the most important library in the tidyverse. It contains a bunch of functions that allow you to work with data frames like extract columns, modify columns, and filter based on conditions.


The main dplyr functions to master are:

- `select()`: extract columns from your data frame

- `filter()`: filter to rows of your data frame based on a condition

- `mutate()`: add columns or modify columns in your data frame

- `summarize()`: aggregate information in your columns

- `group_by()`: perform an operation separately for each value of a categorical column

The rest of this chapter will guide you through using these functions step by step, showing not only how they work individually but also how to combine them. Once you're comfortable with these functions, you’ll be ready to tackle a variety of data analysis tasks.



## Select() for extacting columns

We can use the `select()` function to extract specific named columns from our data frame. 

- The *first argument* of `select()` is always the data frame on which you are operating.

- All of the *remaining arguments* of `select()` are the names of the columns that you want to keep. 

Note that the column names do *not* have quotes around them. This is something that makes dplyr (and tidyverse) functions special.

So if we want to use `select()` to extract just the `country`, `year`, and `lifeExp` columns from our `gapminder` data frame, the first argument will be the name of our data frame object, `gapminder`, and the subsequent arguments will be the names of the columns we want to extract:

```{r}
select(gapminder, country, year, lifeExp)
```


Note that I haven't *modified* the original `gapminder` data frame object here. If I print `gapminder`, it still has all of the original columns:


```{r}
gapminder
```


Instead, I have created a *new* data frame with just the `country`, `year`, and `lifeExp` columns, and I've just printed it out. 

If I wanted to *use* this `country`, `year`, and `lifeExp` subsetted data frame, I would need to save it as a new variable/object using the `<-` assignment operator:

```{r}
gapminder_subset <- select(gapminder, country, year, lifeExp)
```


And I could then work with this new data frame by referencing `gapminder_subset` in my code:

```{r}
gapminder_subset
```

In this chapter, however, I will typically print the output of various data frame operations without saving the resulting data frame output as new objects. This is because I just want to show what the result will be. I don't necessarily need to use the resulting data frames for anything (so there is no point in saving them as new objects).

### Removing columns with `select()`

You can remove columns by using a minus sign in front of the column name. For example, the following code will return the `gapminder` data frame *without* the `continent`, `year`, and `pop` columns:

```{r}
select(gapminder, -continent, -year, -pop)
```

### Renaming columns with `select()`

`select()` can also help you rename columns. If you provide a named argument for your columns as `new_name = old_name`, the resulting column in the output data frame will be renamed to whatever you provide as `new_name`. For example, the following code will return the `gapminder` data frame with the `country`, `year`, `lifeExp`, and `gdpPercap` columns, except the `lifeExp` column will be renamed to `life_exp` and the `gdpPercap` column renamed to `gdp_per_cap`:

```{r}
select(gapminder, country, year, life_exp = lifeExp, gdp_per_cap = gdpPercap)
```

### Renaming columns with `rename()`

However, since `select()` will only return the columns included in its arguments. If you want to rename a column without also having to list all the other columns you want in your output data frame, you can use the `rename()` function instead. 

For example, the following code will return *all columns* in the `gapminder` data frame, with the `lifeExp` column renamed to `life_exp` and the `gdpPercap` column renamed to `gdp_per_cap`:


```{r}
rename(gapminder, life_exp = lifeExp, gdp_per_cap = gdpPercap)
```

:::: {.panel-tabset}

## Question

What would happen if I replaced `rename()` in the code above with `select()`? As in:

```{r}
#| eval: false
select(gapminder, life_exp = lifeExp, gdp_per_cap = gdpPercap)
```


## Answer 

The resulting data frame output would *only* include the `life_exp` and `gdp_per_cap` columns!

```{r}
select(gapminder, life_exp = lifeExp, gdp_per_cap = gdpPercap)
```


::::







## The pipe `|>` (formerly known as `%>%`)

Before introducing our next dplyr function, I want to introduce you to an operator called the **pipe**. The pipe is literally (in my very biased opinion) the best coding invention ever. 

The pipe, `|>`, allows us to read our code as if it is a sentence. For example, if I wanted to turn the following sentence "*I take my backpack and then I put books in it and then put it on my back*" using the pipe, I would write `backpack |> put_books_in() |> put_on_back()`. I always think of the pipe operator `|>` as the word "and then" in a sentence. 

Take a look at the following code:

```{r}
gapminder |> select(country, year, lifeExp)
```

I read this code in my head as "*take the gapminder data frame and then select the country, year, and lifeExp columns*":


The pipe syntax is: `object |> function()`. The way it works is that the object to the left of the pipe (`object`) is placed into the *first argument* of the function to the right of the pipe (`function()`).

This means that the following two pieces of code are equivalent:

```{r}
# apply head() to gapminder directly
head(gapminder)
# apply head() to gapminder using the pipe
gapminder |> head()
```

The second version with the pipe takes the `gapminder` data frame (which is to the left of the pipe) and places it into the (first) argument of the `head()` function on the right of the pipe. The pipe always has an object (like a data frame) on its left and a function on its right.

Here is another example of two pieces of equivalent code, first, without the pipe:

```{r}
# without the pipe
select(gapminder, year, pop)
```

Second, with the pipe ("take the `gapminder` data frame *and then* select the `year` and `pop` columns"):

```{r}
# with the pipe
gapminder |> select(year, pop)
```

Remember that the pipe places the object on the left of the pipe into the *first* argument of the function on the right of the pipe. The `select()` function, however, takes many arguments. If the function to the right of the pipe `|>` takes more than one argument, then the remaining arguments are just included inside the parentheses of the function on the right of the pipe.


:::{.callout-tip}
## The "new" pipe `|>` versus the "old" pipe `%>%`

The pipe `|>` is now a part of the "base R" programming language. Previously, you needed to load the "magrittr", "dplyr", or "tidyverse" libraries to access the pipe and it had a different symbol: `%>%`. 

The two pipes behave very similarly. The main difference I noticed when I switched was that the old pipe didn't require parentheses for functions that didn't have any additional arguments, e.g., you could write `df %>% head`. But the new pipe requires the empty parentheses after the function, as in: `df |> head()`. 

The old pipe `%>%` still works, but my recommendation is that you use the newer "native" pipe syntax: `|>`. 
:::




## Filtering rows using filter()

Our next dplyr function, `filter()`, lets you filter to specific rows based on a logical condition.

Imagine that we just want to look at the rows in the `gapminder` data frame whose `country` value is `"Australia"`. Then we can write:

```{r}
filter(gapminder, country == "Australia")

```

Where:

- The first argument of `filter()` is the data frame (`gapminder`) that you want to operate on.

- The second argument of `filter()` is the *logical condition* involving the column of the data frame that you want to use to filter (`country == "Australia"`).

 `filter()` will return all rows for which the provided condition is `TRUE`. Note that in our condition, we do *not* need quotes around the column name, `country`, but we *do* need quotes around the value, `"Australia"`. Remember that when asking a logical question of equality, we need to use two equal signs `==`. 


Now that we have met our trusty pipe, we can rewrite this `filter()` code as:

```{r}
gapminder |> filter(country == "Australia")
```

Remember that the pipe, `|>`, places the object on the left-hand side (`gapminder`) into the first argument of the function (`filter()`) on the right-hand side.

### Multiple filtering conditions

You can provide multiple conditions to `filter()` as separate arguments. Given multiple conditions, `filter()` returns the rows for which *all* of the provided conditions are `TRUE`.

For example, the following code will filter the `gapminder` data frame to the rows where both `country == "Australia"` AND `year > 1990` are `TRUE`. 

```{r}
gapminder |> filter(country == "Australia", year > 1990)
```

Take note of when we do and when we do not need quotes. We never need quotes when referencing a column name from our data frame inside a dplyr function, nor do we need quotes for numeric values, such as `1990`. We do, however, need quotes when referencing a *character* value, such as `"Australia"`. 

You can read this code (`gapminder |> filter(country == "Australia", year > 1990)`) as "take the gapminder data frame *and then* filter to the rows where the country is Australia and the year is greater than 1990".


To start to get a sense of why the pipe is so useful, let's use it to combine some sequential `filter()` and `select()` operations:

- Filter to the rows where the `continent` column is `"Africa"` and the `year` column is `1992`.

- Select just the `country` and `lifeExp` columns (renaming `lifeExp` to `life_exp`).

```{r}
gapminder |> 
  filter(continent == "Africa", year == 1992) |> 
  select(country, life_exp = lifeExp)
```

Note that I like to start a new line *after* each pipe `|>` to make the code more readable. 

How would you read the code above as a sentence? I read it as "take the gapminder dataset *and then* filter to just the rows where the `continent` column is equal to `"Africa"` and the `year` column is equal to `1992` *and then* select just the `country` and `lifeExp` columns, renaming `lifeExp` to be `life_exp`".

Since the output of just the first filtered part of the above code, `gapminder |> filter(continent == "Africa", year == 1992)`, is a data frame itself, when I add another pipe `|>` after this first operation, I am piping the resulting filtered data frame into the subsequent `select()` function.

If I wanted to try to write this code *without* the pipe, I would have to do it in a few steps like this:

```{r}
gapminder_africa_1992 <- filter(gapminder, continent == "Africa", year == 1992)
select(gapminder_africa_1992, country, life_exp = lifeExp)
```

This code does the same thing, but without the pipe, I am forced to define an intermediate object, `gapminder_africa_1992` (or do some disgusting nested function stuff), which feels inferior to the pipe-based approach. The pipe allows me to do all this in a single, more readable, and more efficient operation.



### The order of operations

It turns out that the order of operations when conducting dplyr operations can be fairly important.

For example, if I swap the order of `select()`  and `filter()` in the code above, I will get an error:

```{r}
#| error: true

# swap the filter and select steps above
gapminder |> 
  select(country, life_exp = lifeExp) |>
  filter(continent == "Africa", year == 1992) 
```

Why do you think this happens? Take a look at the error message for a hint. R is telling us that there is no `continent` column. What data frame is being piped into the `filter()` function? 

Let's run just the first two lines of code to find out:


```{r}
gapminder |> 
  select(country, life_exp = lifeExp) 
```

This is the data frame that is being piped into `filter()`. Does it contain a `continent` column? No, it does not! So the `filter()` function is trying to filter this two-column data frame to just the rows for which it's `continent` column is equal to `"Africa"`, but this two-column data frame doesn't contain a `continent` column!

The following two pieces of code are therefore *not* equivalent:

```{r}
#| eval: false
gapminder |> 
  filter(continent == "Africa", year == 1992) |>
  select(country, life_exp = lifeExp) 
  
```


```{r}
#| eval: false
gapminder |> 
  select(country, life_exp = lifeExp) |>
  filter(continent == "Africa", year == 1992) 
```


### Filtering using "OR" conditions

How would you filter to the rows where country corresponds to "Australia" and "Italy"? You might imagine that you can provide these two conditions separated by a comma, as in:

```{r}
gapminder |> filter(country == "Australia", country == "Italy")
```


However, this has returned an *empty* data frame with 0 rows. Why has this happened?

Remember that whenever you provide two conditions to `filter()` with a comma, R filters to the rows where *both* conditions are true. That is, a comma corresponds to an "AND" condition.

`filter(country == "Australia", country == "Italy")` means "filter to the rows where `country == "Australia"` AND `country == "Italy"` are both true. However, there are no rows where `country` is simultaneously equal to `"Australia"` and `"Italy"`. It is only ever equal to one or the other. 

Although I phrased my desire as "filter to the rows where `country` corresponds to Australia **and** Italy", I really meant, "filter to the rows `country` corresponds to Australia **or** Italy".

Can you remember how to ask an "OR" question? You use the vertical bar `|`. So to provide an "OR" condition, I could provide my two conditions separated by a vertical bar, `(condition 1) | (condition 2)`, which will return all rows where *either* condition 1 *or* condition 2 are satisfied:


```{r}
gapminder |> 
  filter((country == "Australia") | (country == "Italy")) 
```



Here R is trying to be helpful by only printing the first 10 rows. I can tell it to print all 24 by piping my data frame into a `print()` function:

```{r}
gapminder |> 
  filter((country == "Australia") | (country == "Italy")) |>
  print(n = 24)
```

If both conditions involve the same variable (in this case, `country`), you can instead use the `%in%` operator! Remember that you can ask which values in a vector are also in some other vector, such as asking which values in the vector `c(1, 5, 2, 2, 1, 6)` are equal to `1` or `2` (i.e., are in the vector `c(1, 2)`) by writing:

```{r}
c(1, 5, 2, 2, 1, 6) %in% c(1, 2)
```


We can use this same `%in% `operator to ask which entries of the `country` column are equal to `"Australia"` or `"Italy"`:

```{r}
gapminder |> 
  filter(country %in% c("Australia", "Italy")) |>
  print(n = 24)
  
```


:::: {.panel-tabset}

## Exercise

Filter `gapminder` to all countries on the `"Oceania"` continent for just the years 1987 and 1992 and select just the `country`, `year`, and `gdpPercap` columns (and rename `gdpPercap` to be `gdp_per_cap`). 

Save the output in an object called `gapminder_oceania`, and print `gapminder_oceania` to the console.

## Solution

```{r}
gapminder_oceania <- gapminder |> 
  filter(continent == "Oceania", year %in% c(1987, 1992)) |>
  select(country, year, gdp_per_cap = gdpPercap)
gapminder_oceania
```


::::











## Adding and modifying columns using mutate()

Next, let's learn how to add and modify columns in our data frame using `mutate()`.

If I wanted to add a new column to my data, called `gdp`, which is the product of the `pop` and `gdpPercap` columns, I can do that using `mutate()`. 

```{r}
gapminder |> mutate(gdp = pop * gdpPercap) 
```

Here, `gdp`, is the name of my new column, and `pop` and `gdpPercap` are existing columns in my data frame, so I don't need to use quotes.

Remember that the code above hasn't actually modified `gapminder`. To modify `gapminder` I would need to *reassign* `gapminder` to the mutated dataframe: `gaminder <- gapminder |> mutate(gdp = pop * gdpPercap)`.

What this code has done is it has created a brand new column, `gdp`, and placed it at the end of my data frame (and printed out the resulting data frame without saving it as a new variable). In this case, each value in the `gdp` column contains product of the corresponding values in the `pop` and `gdpPercap` columns.


As another example, if we wanted to create a new column that contained the population in millions, i.e., `pop` divided by 1 million, we could do that using:

```{r}
gapminder |> mutate(pop_mil = pop / 1e6)
```


Note that `1e6` is scientific notation for `1000000` (i.e., `1` followed by 6 `0`s).

While `mutate()` is often used to create *new* columns, it can also be used to *modify existing* columns. For example, the code below will modify the existing `lifeExp` column by rounding it to the nearest integer. 

```{r}
gapminder |> mutate(lifeExp = round(lifeExp)) 
```

Note that no new columns have been added to the end of our `gapminder` output. The data frame contains the exact same columns as the original `gapminder` object, except the `lifeExp` column is now a rounded integer!




:::: {.panel-tabset}

## Exercise

Create the following data frame (there is a new `log_pop` column, and the `gdpPercap` column has been rounded to the nearest integer):

```{r}
#| echo: false

gapminder |> 
  mutate(log_pop = log(pop), gdpPercap = round(gdpPercap)) 
```



## Solution

```{r}
gapminder |> 
  mutate(log_pop = log(pop), gdpPercap = round(gdpPercap)) 
```

::::









## Summarizing data frames using summarize()

The functions that we have discussed do far in this chapter (`select()`, `filter()` and `mutate()`) are all functions that can be used to modify your data frame.

In this section, we will introduce `summarize()`, which can be used to--you guessed it--*summarize* your data frame.

As an example, let's summarize our data frame by computing the mean `lifeExp` value across all rows in the dataset:

```{r}
gapminder |> summarize(mean(lifeExp))
```


You can read this as: "take the `gapminder` dataset *and then* summarize it by computing `mean(lifeExp)`, i.e., the mean of the `lifeExp` column".


However, like all of the other functions we have used in this chapter, the output of `summarize()` function is itself a data frame (albeit with just a single row and column). But notice that the name of the column in our summary data frame is just the function that was computed, `mean(lifeExp)`. Wouldn't it be nice if we could give this column a nicer name? Fortunately, this is super easy to do by providing a name for our summary operation inside the summary() function:

```{r}
gapminder |> summarize(mean_life_exp = mean(lifeExp))
```

In this version, our one-row-one-column data frame has the column name `mean_life_exp`, instead of `mean(lifeExp)`. 




It's also super easy to compute multiple summaries at once using our trusty comma:

```{r}
gapminder |> 
  summarize(mean_life_exp = mean(lifeExp), 
            max_population = max(pop))
```


You don't have to put each summary computation on a new line as I did here, but it makes it a bit easier to read (e.g., compared with ` summarize(mean_life_exp = mean(lifeExp), max_population = max(pop))`).

## Grouped operations with group_by()

Computing a `summary()` operation across all of the rows at once is nice and all, but I'll forgive you if you're sitting there thinking "Ok Rebecca, I know you love the tidyverse, and you want to pipe everything into everything else, but honestly it's just easier to use base R notation to do this, like:"

```{r}
mean(gapminder$lifeExp)
```

And my response to you would be: yeah. It is. But just wait. The next thing I'm going to show you will blow your mind. 

What if I asked you to compute the average life expectancy again, but to do it separately *for each continent*. 

While you could precede your `summarize()` operation with a `filter()` operation separately for each continent like this:

```{r}
gapminder |> filter(continent == "Asia") |> summarize(mean(lifeExp))
gapminder |> filter(continent == "Americas") |> summarize(mean(lifeExp))
gapminder |> filter(continent == "Africa") |> summarize(mean(lifeExp))
gapminder |> filter(continent == "Europe") |> summarize(mean(lifeExp))
gapminder |> filter(continent == "Oceania") |> summarize(mean(lifeExp))
```


Or even use a "for" loop (if you so desired...), it turns out that there is a better way!

The true value of the `summarize()` function lies in its friendship with the `group_by()` function. The following code concisely computes the average `lifeExp` separately for each `continent` by "grouping" the `gapminder` data frame by `continent` (using `group_by()`) *before* summarizing.

```{r}
gapminder |> 
  group_by(continent) |> 
  summarize(mean_life_exp = mean(lifeExp))
```


You can think about this as if `group_by()` is creating a separate data frame for each `continent` value and then it is computing the `summarize()` operation *separately* for each continent data frame, and it is then combining the summary output into a two-column data frame, where the first column contains the respective `continent` value, and the second column contains the result of the `summary()` operation for that particular continent.

Now that's rad as heck!


:::: {.panel-tabset}
## Exercise

Use group_by() and summarize() to compute the standard deviation of the `gdpPercap` column separately for each country.

Your output should look like this:

```{r}
#| echo: false
gapminder |> 
  group_by(country) |> 
  summarize(sd_gdp = max(gdpPercap))
```

## Solution

```{r}
gapminder |> 
  group_by(country) |> 
  summarize(sd_gdp = max(gdpPercap))
```
::::







### Grouping by multiple columns simultaneously

Just in case you weren't already impressed enough by the `group_by()`/`summarize()` duo, you can also do more sophisticated grouping operations, such as computing the average `lifeExp` for each continent-year *combination* by grouping by both `continent` and `year`:

```{r}
# compute the average life expectancy for each continent-year combination
gapminder |> 
  group_by(continent, year) |> 
  summarize(mean_life_exp = mean(lifeExp))
```


With `filter()`, `mutate()`, `group_by()`, and `summarize()` up your sleeve, there is almost no summarization of your data you can't do!


:::: {.panel-tabset}
## Exercise

Compute the mean and standard deviation of the GDP (the product of `pop` and `gdpPercap`) separately for each continent and year after the year 2000. Your output should look like this:

```{r}
#| echo: false
#| message: false
gapminder |>
  filter(year > 2000) |>
  mutate(gdp = pop * gdpPercap) |>
  group_by(continent, year) |>
  summarize(mean(gdp))
```

## Hint

My suggested order of operations is 

```{r}
#| eval: false
gapminder |>
  filter() |>
  mutate() |>
  group_by() |>
  summarize()
```

## Solution

```{r}
gapminder |>
  filter(year > 2000) |>
  mutate(gdp = pop * gdpPercap) |>
  group_by(continent, year) |>
  summarize(mean(gdp))
```
::::



### Grouped mutates

Although `group_by()` is most often used with `summarize()`, this doesn't mean that it can *only* be used with `summarize()`!


Below, I group by `continent` and then conduct a `mutate()` to add a new column `max_life_exp`, containing the maximum life expectancy for the corresponding country. This time, I save the resulting data frame in a new variable called `gapminder_new`:

```{r}
gapminder_new <- gapminder |> 
  group_by(country) |>
  mutate(max_life_exp = max(lifeExp)) 
# print the first 30 rows of gapminder
print(gapminder_new, n = 30)
```

Take a close look at the new `max_life_exp` column that I've tacked onto the end of my data frame. Notice that it contains a single value for each country corresponding to the average `lifeExp` value computed using just the rows for that country.


### Don't forget to `ungroup()`

So we've got our `gapminder_new` object that contains our `max_life_exp` column which contains the maximum life expectancy value where the average is computed just using the corresponding country's rows.

If I then wanted to conduct a subsequent summarize operation on this `gapminder_new` object, such as computing the mean of this new `max_life_exp` value, with the goal of computing this average *over all rows in the data* (i.e., I should get a single value), I might write the following code:

```{r}
gapminder_new |> summarize(mean(max_life_exp))
```


Is there anything surprising about the output here? The `summary()` operation is still *grouped by country*, even though I didn't conduct another `group_by(country)` operation before my `summarize()` operation!

This is because `gapminder_new` is not technically a simple data frame... it is a *grouped* data frame.  Notice the text at the top of the output:


```{r}
gapminder_new
```

It says `# Groups:   country [142]`, which tells me that `gapminder_new` is *grouped* by the country column (and there are 142 groups). This means that any subsequent operations that I conduct on `gapminder_new` will also be grouped (by `country`). 


If you are going to continue working with a data frame that was created using a `group_by()` operation, it is important to remember to `ungroup()`, unless you also want your subsequent operations to be grouped:

```{r}
gapminder_new |> 
  ungroup() |> 
  summarize(mean(max_life_exp))
```

I could write all of this code without defining my intermediate `gapminder_new` object as follows:

```{r}
gapminder |> 
  group_by(country) |>
  mutate(max_life_exp = max(lifeExp)) |>
  ungroup() |>
  summarize(mean(max_life_exp))
```

But if I forgot the `ungroup()` operation (the second-last line above), I get:

```{r}
gapminder |> 
  group_by(country) |>
  mutate(max_life_exp = max(lifeExp)) |>
  summarize(mean(max_life_exp))
```


### Grouped filtering

You can also conduct grouped filtering, which will apply your filter condition separately for each group. The most common scenario in which I find myself doing this is when I want to do something like filtering to the row in each group with the maximum value in one of the columns, such as filtering to the rows with the highest `lifeExp` separately *within each continent*:

```{r}
gapminder |>
  group_by(continent) |>
  filter(lifeExp == max(lifeExp))
```


## Count

Another really useful function is `count()`, which is used to summarize categorical (character/factor) variables. 


`count()` creates a two-column data frame, where the first column displays the unique values of the provided column from the original data frame, and the second column, `n`, contains the number of times that each unique value appears:

```{r}
gapminder |>
  count(continent)
```

This shows that the `"Africa"` continent value appears in the data 624 times, the `"Americas"` continent value appears 300 times, and so on.





## Arrange

The final function I will show you in this chapter is `arrange()`, which lets you arrange the rows of your data frame in ascending or descending order of the values in a specific column. By default, `arrange()` will arrange the rows in ascending order of the values in the provided column. 

The following code will rearrange all of the rows so that the row with the smallest `lifeExp` value will be at the top and the row with the largest `lifeExp` value will be at the bottom:

```{r}
gapminder |>
  arrange(lifeExp)
```


For some reason, the way that you specify that the rows should be arranged in *descending* order instead is to wrap the variable name in the `desc()` function. The following code will arrange the `gapminder` rows so that the row with the largest `lifeExp` value will be at the top and the row with the smallest `lifeExp` value will be at the bottom:

```{r}
gapminder |>
  arrange(desc(lifeExp))
```

Technically, you could also arrange by the negative of the column to arrange in descending order, but I usually use the `desc()` approach. 

```{r}
gapminder |>
  arrange(-lifeExp)
```









Here are a bunch of challenging exercises for you to test your dplyr skills. These are intentionally hard!

:::: {.panel-tabset}

## Exercise

Compute the *median* `lifeExp` and maximum `pop` values for each country, and then arrange the countries in descending order of their maximum `pop` value.

## Solution

```{r}
gapminder |>
  group_by(country) |>
  summarize(median_life_exp = median(lifeExp),
            max_pop = max(pop)) |>
  arrange(desc(max_pop))

```
::::

:::: {.panel-tabset}

## Exercise


Identify the 5 countries with the highest *average* life expectancy.

## Solution

```{r}
gapminder |>
  group_by(country) |>
  summarize(mean_life_exp = mean(lifeExp)) |>
  ungroup() |>
  arrange(desc(mean_life_exp)) |> 
  head(5)
```

::::

:::: {.panel-tabset}

## Exercise

What are the three most populous countries on the "Asia" continent?

## Solution

```{r}
gapminder |>
  filter(continent == "Asia") |>
  group_by(country) |>
  summarize(max_pop = max(pop)) |>
  ungroup() |>
  arrange(desc(max_pop)) |>
  head(3)
```
::::


:::: {.panel-tabset}

## Exercise

Identify the country with the highest total GDP for each continent.

## Hint

Apply a `filter()` after a `group_by()` -- this will apply the filtering separately for each group.

## Solution

These are the countries with the highest total GDP for each continent:

```{r}
gapminder |>
  mutate(gdp = gdpPercap * pop) |>
  group_by(continent) |>
  filter(gdp == max(gdp)) |>
  select(country, continent, gdp)
```

::::

:::: {.panel-tabset}

## Exercise

Compute the average GDP per capita for each continent based only on countries with `gdpPercap` greater than 20,000.

## Solution

```{r}
gapminder |>
  filter(gdpPercap > 20000) |>
  group_by(continent) |>
  summarize(mean(gdpPercap))
```

::::