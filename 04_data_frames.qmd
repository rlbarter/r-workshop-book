---
title: "Data Frames"
format: html
editor_options: 
  chunk_output_type: console
---




Let's imagine that you have an actual dataset containing a collection of columns ("variables" in data terminology) and rows ("observations" in data terminology). For example, maybe your dataset is:


|Name|Age|Favorite Color|
|:----|:----|:----|
|Dean | 12 | Blue |
|Xiao | 18 | Green |
|Sara | 22 | Red |
|Ravi | 21 | Purple |
|Maya | 17 | Blue |

In this case, your dataset has three *"variables"* (name, age, and favorite color), and five *"observations"* for each of these variables (corresponding to the values for 5 unique people). You might even recognize this data from the previous chapter: the values in the "Age" column are the values from our `age` vector and the names correspond to the names that we gave our age vector, along with some extra "Favorite Color" information.

While we could define a separate vector variable in R for each column in our data, such as

```{r}
# three vectors containing info on each person's name, age, and favorite color
name_vec <- c("Dean", "Xiao", "Sara", "Ravi", "Maya")
age_vec <- c(12, 18, 22, 21, 17)
color_vec <- c("blue", 'green', 'red', 'purple', 'blue')
```

Once we started analyzing this data, it would quickly become hard to keep track of which age corresponded to which name, and what their corresponding favorite color is since the variables are each stored in three separate objects. For example, if I look at the `color_vec` vector by typing its name:

```{r}
color_vec
```

It isn't clear whose color preference is whose.

It would be much nicer if we could create a *single* object containing all three of these variables such that the corresponding values are "aligned" in such a way that it is very clear that "Ravi" has age 21 and favorite color "purple".

Fortunately, the creators of R share our desires, so they let us store each of our vectors in an object called a "**data frame**". 

If I already have the columns of my data stored as separate vectors, I can create a data frame using the `data.frame()` function as follows:

```{r}
my_data <- data.frame(name = name_vec,
                      age = age_vec, 
                      color = color_vec)
```

Where the name to the left of the `=` symbol in my `data.frame()` arguments defines the corresponding "column name" in my data frame.

Since `my_data` is an R object, I can view it by typing its name:

```{r}
my_data
```

Now our three variables are neatly arranged in rows and columns, where there is one row for each person and one column for each variable *and* this is all stored in a single variable/object called `my_data`. 

The integer numbers 1, 2, 3, 4, and 5 shown along the left-hand side of the rows are not actually a part of the data object itself (notice that there is no "column name" printed above these integers). These numbers are just visual aids provided by the R console when you print a data frame object to make it a little bit easier to count the rows in the data.


If I ask R what kind of object `my_data` is, it tells me it's a "data.frame". 

```{r}
class(my_data)
```

And I can get a quick summary of what my data frame contains using the `str` function:

```{r}
str(my_data)
```

In particular, the things that I find helpful in this summary are the number of "obs." (5) and "variables" (3), and the type/class of each variable shown after its name, which tells me that the `name` and `color` columns have a "chr" (character) type, and the `age` variable has a "num" (numeric) type. 

Each column in a data frame can have a different type, but *each entry within a single column must be the same type* (because each column corresponds to a vector).

There are several techniques for extracting the vectors stored in a data frame. For instance, if I wanted to extract the `age` column, or specifically, the vector corresponding to the `age` column, I can write:


```{r}
my_data$age
```

or 

```{r}
my_data['age']
```

These two approaches both extracted the `age` column, but notice that the output of these two column extraction techniques look a little different. 

Can you guess why? Hint: What type/class do you think each output object has? Look at its formatting. Learning to recognize what type each object has based on the way it looks is a really helpful skill. 

The output of `my_data$age` *looks* is an ordinary vector. I can tell because the values are arranged horizontally, and there is a `[1]` at the beginning of the output. But this isn't the case for the output of `my_data['age']`. The output here looks more like our data frame output (but with only one column).

Indeed, if I ask R to tell me the class of each of these two objects that I have extracted, I learn that the `my_data$age` object has a "numeric" type (remember that a vector containing numeric values will have a "numeric" type!)

```{r}
class(my_data$age)
```

And I learn that the `my_data['age']` object has a "data.frame" type:

```{r}
class(my_data['age'])
```

Since data frames and vectors have different behaviors, there will be some scenarios where you prefer your extracted column to be a vector, and others where you will prefer your extracted column to be a single-column data frame.

While I occasionally want to extract columns from my data as a vector using one of these techniques, I typically conduct my data analyses and modifications on the data frame object itself. You'll encounter some sophisticated techniques for working with data frames in the next chapter. But first, I want to show you how to load a dataset that you have saved on your computer into a data frame in R.


## Loading data from external files


To create the `my_data` data frame object above, I first created the individual vectors, which I then used to define the columns of my data frame within the `data.frame()` function. Imagine if your data had hundreds of observations/values for each of hundreds of variables. No one wants to manually type their data into R. 

More often than not, the data you want to analyze will already live in a file on your computer, such as a .csv file or an Excel spreadsheet. In this section, I will show you how to "load" data from such files into an R data frame.




### Loading data from .csv data files

.csv files are one of the *simplest* data formats. "csv" stands for "comma separated value". In a .csv file:

- Columns are separated by commas

- New rows are created by starting a new line

The .csv version of our data above looks like this:

```{verbatim}
name, age, color
Dean, 12, blue
Xiao, 18, green
Sara,  22, red
Ravi, 21, purple
Maya, 17, blue
```


To load in a dataset (as a data frame) from a .csv file, we can use the `read.csv()` function. However, for R to be able to find your file you need to provide a "filepath" argument (as a character/text value) to your csv file.

The file path corresponds to the location where your file lives on your computer relative to where the current R file you are working in is saved. Ideally, you are working in a quarto document. If so, identify where on your computer you have saved your quarto document. If your csv data file lives in the same folder as your quarto document, then you will write 

```{r}
#| eval: false
data <- read.csv("filename.csv")
```

where you replace `"filename.csv"` with the actual file name of your .csv file. 

If your .csv data file lives in a `data/` subfolder, then you will write 

```{r}
#| eval: false
data <- read.csv("data/filename.csv")
```

When you compile a quarto document (which will involve sequentially running all of the code in the code chunks), R automatically searches for any referenced files in the folder where the quarto document is saved.

However, if you run the code in the console, R might not automatically know to look for files in the same folder as your quarto document. To ensure R can locate your files, your console's working directory needs to match the folder containing your quarto document. The **working directory** is the folder where your R console looks for files to load (and where it saves any files you create).

All file paths in code that is run in the console are relative to your console's current working directory, regardless of where your quarto document is saved.

If you open RStudio by directly opening a quarto document or an R script, the working directory is typically set to the folder containing that file. However, if you open your IDE without opening a specific file, the working directory is likely set to your computer's home folder.

If the console's working directory doesn’t match the folder where your quarto document or R script is saved (the location of the code you're running), R won’t be able to find your data files.

::: {.callout-tip}
## Identifying the console's current working directory

You can see your console's current working directory by looking at the top of the console. In the image below, the working directory is the "Documents" folder. If you just see `~`, then your console's current working directory is your computer's home folder.

```{r}
#| echo: false
knitr::include_graphics("figures/working_directory.png")
```

:::

:::{.callout-tip}
## Changing your console's working directory

It is recommended that your working directory matches the location of the quarto document you are working in. 

You can update your console's working directory to be the location of your current quarto document in RStudio by choosing "Session > Set Working Directory > To Source File Location". 
:::


Let's load an actual .csv file. If you are working in a quarto document or an R script on your computer, take note of where you saved it. Then [download the following "data" folder containing the "gapminder" dataset](https://github.com/rlbarter/r-book/raw/refs/heads/main/data/data.zip) and move the data folder to the same location as your current quarto document.

If you are working in a quarto document called "analysis.qmd" then your folder should have the following structure, in which the "data" folder lives in the same place as "analysis.qmd":

```{r}
#| echo: false
#| out.width: 250
#| fig.align: "center"
knitr::include_graphics("figures/data_folder.png")
```



Then, assuming that your console's working directory matches the location of your quarto document on your computer, you should be able to run the code below to load in the gapminder.csv data file and save it as a data frame object called `gapminder`:

```{r}
gapminder <- read.csv(file = "data/gapminder.csv")
```

If you get an error that says `"Warning message: In file(file, "rt") : cannot open file 'data/gapminder.csv': No such file or directory"`, this means that either you did not move the "data" folder containing "gapminder.csv" in the right place, or your console's working directory is incorrect!

Hopefully you figured out how to tell R to find and load your dataset! If your code above worked, you should then be able to take a look at the `gapminder` object by typing its name:

```{r}
#| attr-output: 'style="height: 400px"'
gapminder
```

This prints out A LOT of data (I've contained the output in a nice scrolly box, but if you did this in a standard quarto document or in your console, the entire thing will be printed out, sans scrolly box). In general, you want to avoid printing your entire dataset in your R console or rendered quarto document. 

Instead, try printing just the first few (6, to be exact) rows using the `head()` function:

```{r}
head(gapminder)
```

Now that we are starting to get a handle on our gapminder data frame, let's talk about the information it contains. The gapminder dataset contains information on life expectancy, population, and GDP per capita for 142 countries every 5 years between 1952 to 2007. Each country has 12 rows in the data, one for each year.

If you want to learn more about the gapminder dataset, head on over to the [gapminder website](https://www.gapminder.org/).


## Attributes of a data frame

Often I find it helpful to print out just the column names of a data frame using the `colnames()` function:

```{r}
colnames(gapminder)
```

We can also ask things like how many rows our data frame has using the `nrow()` function:

```{r}
nrow(gapminder)
```


We can ask how many columns our data frame has using the `ncol()` function:

```{r}
ncol(gapminder)
```

Or we can ask both how many rows and how many columns our data frame has at the same time using the `dim()` function:

```{r}
dim(gapminder)
```



We can use our trusty `str()` function from earlier to take a sneak peek at the "structure" of our data:

```{r}
str(gapminder)
```

And we can use the `summary()` function to get some statistical summaries (like the minimum, median, mean, maximum, and the quartiles) of each of the numeric columns in our data frame (this summary is fairly useless for character/categorical columns though):

```{r}
# use summary() to look at a summary of gapminder
summary(gapminder)
```



:::: {.panel-tabset}

## Exercise

Your turn: [download the following world happiness dataset](https://github.com/rlbarter/r-book/raw/refs/heads/main/data/whr.zip). Load the `whr_2023.csv` file into R, saving it as a variable called `world_happiness`. 

Then print out the first 6 rows, the column names, create a summary of the data, and report its dimension.


## Solution

Loading the data

```{r}
world_happiness <- read.csv("data/whr_2023.csv")
```

Printing the first 6 rows:
```{r}
head(world_happiness)
```

And looking at several features of the data:

```{r}
str(world_happiness)
summary(world_happiness)
```


```{r}
dim(world_happiness)
```

::::



## Loading data from Excel, SPSS, Stata, and SAS files 

Loading data from Excel, SPSS, Stata, and files is almost as easy as loading data from .csv files, except that you will need to install some add-on packages to do so. Specifically, to load Excel files, you will need to install the "readxl" package, and to load SPSS, Stata, or SAS files, you'll need to install the "haven" package.

You'll learn about installing and loading packages in the next chapter. [Click here](https://readxl.tidyverse.org/) to learn more about loading data from Excel files and [click here](https://haven.tidyverse.org/) to learn more about loading data from SPSS, Stata, and SAS files.